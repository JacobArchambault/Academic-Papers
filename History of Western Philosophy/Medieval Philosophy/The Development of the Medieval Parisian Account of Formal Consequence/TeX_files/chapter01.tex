\chapter{Introduction}

%opening

	
	\section{Formal consequence and formal logic}
	Logic is commonly singled out for special consideration among the sciences by the dictum `logic is formal'. We speak about formal rigor, formalized languages, formal consequence, formal methods - indeed, only the other branches of mathematics come close to logic in the degree to which they are stamped with the language of formality. Other areas of inquiry are sometimes even considered formal to the degree that they incorporate logic into their methodology - formal epistemology, for instance, is an approach to epistemology heavily reliant on the use of logical apparatus.
	
	The formality of logic is especially present in discussions of logical consequence. This is in part because the subject matter of logic itself is often taken to be \textit{what follows from what} - not, of course, in any sense whatsoever, but as a matter of logical \textit{form}; and in part because as modifiers of `consequence', `logical' and `formal' are frequently taken to be synonymous\footnote{See \cite[188, 193]{Tarski2002}. In what follows, I use `formal' and `logical' interchangeably - not to express agreement with this use, but to address the positions exposited on their own terms.} - a synonymy that, if applied consistently, would transform `logical form' and `formal logic' into the emphatically redundant `formal form' and `logical logic'. In short, the very parlance of logicians suggests the concept of form is at the center of logic.
	
	This dissertation provides an account of how this came about, detailing the development of the notion of formal consequence at the time of the appearance of the first treatises on consequence - the first half of the 14th century - and culminating in the account advanced by John Buridan. Buridan's work provides a convenient focal point from both historical and theoretical perspectives: theoretically, because of its close resemblance to the model-theoretic accounts dominant today; historically, because of its lasting influence on treatments of formal consequence up to the advent of modernity.
	
	\section[Formal consequence from the 20th century]{Formal consequence from the early 20th century to present}
	In order to better understand the development of the notion of formal consequence, it will be useful to say something about the different shapes it takes today. 
		
	In \cite{Tarski2002}, Alfred Tarski considers in turn two approaches to defining logical consequence: the syntactic approach, then represented by the Hilbert school; and the semantic approach, represented in then-recent work by Rudolph Carnap \cite{Carnap1934}. To a surprising degree, approaches to formal consequence continue to fall along these same lines. Semantic approaches, directly traceable to Tarski's own work, remain dominant in both mathematical and philosophical discussions of logical consequence; while through the influence of Gerhard Gentzen, Dag Prawitz and Michael Dummett, a broadly Hilbertian, syntactic approach has been pursued in the tradition of \textit{Proof-Theoretic Semantics}.\footnote{For Gentzen's work, see \cite{Gentzen1934}; cf. \cite{Franks2010}, \cite{Hazen2014}, \cite{Moriconi2015}, \cite{vonPlato2014}. For proof-theoretic semantics, see \cite{Prawitz1974}, \cite{Prawitz1985}; also \cite{Jacinto2017}, \cite{Francez2014a}, \cite{Francez2016a}, \cite{Francez2016b}, \cite{Schroeder-Heister2006}.
		
		Proof-theoretic semantics is frequently coupled with an approach to meaning called \textit{inferentialism}. But not all inferentialists are proof-theoretic semanticists. See \cite{Belnap1990}, \cite{Garson2001}, \cite{Garson2013}, \cite{Hjortland2009}.}
	
	The following survey provides a general account of the major developments in logical consequence from the early twentieth century to today. We begin with a review of developments up to Tarski. After this, we consider more recent developments in the semantic approach, followed by an examination of approaches to logical consequence found in the proof-theoretic tradition.
	\subsection{Formal consequence prior to Tarski}
	\begin{quote}
		{We say that the sentence $X$ \textit{follows logically} from the sentences of the class $\mathfrak{K}$ if and only if every model of the class $\textbf{K}$ is at the same time a model of the sentence $X$.} \cite[186]{Tarski2002}
	\end{quote}
	
	The above quotes the definition of logical consequence offered by Tarski in his now classic `The concept of following logically'. As others have pointed out,\footnote{\cite{Hodges1986} \cite{Etchemendy1988} \cite{Etchemendy2008} \cite{Sher1991}} the definition is not identical to its contemporary successor. And while Tarski's work represented a breakthrough in the development of formalized notions of consequence, it stands not at the beginning, but in the middle of the notion's more recent development.
	\subsubsection{The syntactic approach}
	The ascendant tradition in mathematical logic at the turn of the twentieth century - the logicism of Frege, Russell and Whitehead, and the early Wittgenstein - viewed logic as a discipline whose main concern was the determination logical truth \cite[pp. 74-77]{Etchemendy1988}. This conception of logic allowed the logicist programme to take the particular shape that it had: that of a reduction of mathematics to logic \textit{as} a reduction of mathematical truth to logical truth.\footnote{Without this background conception, Logicists could not take for granted that such a reduction would have counted as one of mathematics to logic.}
	
	Today, a logic is more readily identified with its consequence relation than its logical truths, and, the focus on logical truth appears retrospectively out of place. This focus was in part a function of the dominance of the axiomatic method at the time, but it also had deeper theoretical roots in the program itself \cite{vanHeijenoort1967}. For Russell as for Frege, logic was grounded in reality and universal in scope: the realism of the program lent itself to characterizing logic in a way analogous to other disciplines, as a body of truths;\footnote{Hence, Russell's famous statement that `Logic is concerned with the real world just as truly as zoology, though with its more abstract and general features.' \cite[p. 169]{Russell1919}.} and the universality of the program did not facilitate the adoption of a metatheoretical perspective, \textit{a fortiori} forestalling a metatheoretical investigation into formal consequence. 
		
	Around the same time, Hilbert and his school at Gottingen had succeeded in reducing large parts of mathematics to just a few axioms, along with a few simple rules, such as substitution and detachment, for manipulating these axioms. Hilbert was the first to explicitly describe the project of metamathematics, and with this to detail the problem of whether the consequences of a given set of axioms and rules corresponded with the body of knowledge it was supposed to represent. Thus, though like Frege and Russell early formalism was liable to identify a formal consequence with the truth of its corresponding conditional, it explicitly recognized that identification was one in need of proof. Hence, one finds questions of soundness and completeness, as well as the need for a deduction theorem, coming to the fore in the Hilbert program.\footnote{The first published formulation of the problem of the completeness of propositional logic appears to be in \cite{Hilbert1928}, itself based on Hilbert's lectures from the 1917-18 academic year, notes for which were prepared by Paul Bernays and published in \cite{Ewald2011}. Cf. \cite{Franks2010}.}
	
	%Hilbert and Ackermann's first name
	%find Franks2010 edition number
	In accordance with the aims of the Hilbert school, a consequence is thought to \textit{follow formally} from the axioms and rules of a system iff it is possible to obtain it from those axioms via applications of the permissible rules in a finite number of steps - ideally, in such a manner as to admit a decision procedure for any formula of the language;\footnote{Cf. \cite[354]{Franks2010}.} and the formality of a formal consequence consists in its prescinding from any meaning the manipulated symbols might have.\footnote{\cite{DutilhNovaes2011} calls the notion of the formal involved in this project `the formal as de-semantification'.}
	
	%Relatively early on, the discovery of the $\omega$-incompleteness of arithmetic, as formulated without the addition of rules for infinite induction, showed this notion of formal consequence materially inadequate to the intuitive notion it aimed to capture \cite[177-178]{Tarski2002}. And later, G\"{o}del's incompleteness theorems showed the approach remained inadequate after rules for infinite induction were added, relaxing the finitistic character of the program \cite{Godel1931} \cite[179-181]{Tarski2002}. Lastly, the theorem of Church showed the close connection between formality and computability desired by the formalists fails even in the limited case of first-order logic \cite[321-325]{DutilhNovaes2011}  \cite{Church1936}.
	
	\subsubsection{The semantic approach up to Tarski}
	In \cite{Carnap1934}, Carnap proposed a definition of consequence according to which: 
	\begin{quote}The sentence $X$ \textit{follows logically} from the class of sentences $\mathfrak{K}$ if and only if the class consisting of all sentences of the class $\mathfrak{K}$ and of the negation of the sentence $X$ is contradictory.\end{quote}
	
	Here, Carnap attempts to provide an explicit definition of following from, where the formalist school did not so much define a notion of consequence as presuppose one in its mathematical practice.\footnote{\cite[15]{Hardy1929} provides reason to think this failure was a deliberate part of the formalist enterprise: \quote{Let us observe in passing that there are far more axioms in Hilbert's scheme than in such a scheme as that of \textit{Principia Mathematica}, and \textit{no definitions} in the sense of \textit{Principia Mathematica}. This is inevitable, since it is cardinal in Hilbert's logic that, however the formulae of the system may have been suggested, the `meanings' which suggested them lie entirely outside the system ... The only conceivable sense of a definition in [Hilbert's] system is that of a symbolic convention which instructs us to replace a prolix formula by a more concise one.}} Tarski calls Carnap's definition `The first attempt at the formulation of a precise definition' of following logically \cite[182]{Tarski2002}, though this is incorrect: leaving aside the medieval accounts this dissertation discusses, the concept is defined by Bolzano in the 19th century.\footnote{Bolzano's definition reads as follows: \begin{quote}Propositions \textit{M, N, O, ... follow} from propositions \textit{A, B, C, D, ..} with respect to variable parts \textit{i, j,} ... if every class of ideas whose substitution for \textit{i, j, ...} makes each of \textit{A, B, C, D, ...} true also makes all of \textit{M, N, O, ...} true \cite[209]{Bolzano1972}.\end{quote} \cite{George1986} suggests Bolzano's definition is superior to standard post-Tarskian attempts, inasmuch as it demands the variable parts of a consequence be directly stipulated.} It is probably more correct to say Carnap's notion is the immediate predecessor of Tarski's own, as well as the first attempt to define the notion in the wake of the explosion of interest in foundational research at the turn of the 20th century.
	
	Tarski's definition differs from Carnap's in grounding notions Carnap leaves primitive, thereby widening the range of formalized languages the notion of `following from' is applicable to. For instance, Carnap's definition only applies to languages containing a negation operator, where Tarski's definition is not so restricted; and Carnap's definition leaves `contradictory' undefined, where Tarski's defines `contradictory' in terms of the absence of any model.
	
	One important respect in which the tradition has followed Carnap - and for that matter, Hilbert as well - as opposed to Tarski is on the interpretation of extra-logical symbols of a formal language. For Carnap, the non-logical constants of a language are uninterpreted until specified by a semantic interpretation. Tarski, by contrast, presupposes these symbols already carry a fixed interpretation, in accord with the formalized sphere of inquiry to which they apply \cite[167]{Tarski2002}. Accordingly for Tarski, it is not the \textit{interpretation} of non-logical constants that is varied: rather, these constants are simply replaced. For instance, to evaluate whether the formula $\forall(x)(P(x) \wedge Q(x)) \supset P(x)$ is a logical truth, the standard approach varies the interpretation of $P$ and $Q$, where Tarski's simply replaces these with second-order variables \cite[68-69]{Etchemendy1988}.
	
	\subsection{Formal consequence since Tarski}
	\subsubsection{Semantic developments}
	Since Tarski's work, the semantic account of formal consequence has undergone several developments. 
	
	Tarski applied his definition not to \textit{formal}, but to what he called \textit{formalized} languages, like those for arithmetic and geometry, having a determinate sphere of application. Though he made use of techniques having the effect of domain variation when applying his general definition to subordinate sciences \cite{Gomez-Torrente2009}, Tarski's general conception of a model does not include variations of the domain, while contemporary practice requires this.\footnote{\cite{Etchemendy1988} \cite{Etchemendy2008}. A consequence of this is that for Tarski, the formality of a formalized language is not the same as its universality, since such a language may only be applicable to a restricted domain of objects.}
	
	Indirectly through G\"{o}del's completeness theorem for first-order logic and incompleteness theorems for higher-order logic; and more directly through the philosohpical influence of W. V. O. Quine, logical consequence became ever more associated with the more well-behaved, first-order consequence relation in the postwar period. Quine claimed Higher-order logic, on account of its expressive power, was not logic at all, but rather mathematics in disguise.\footnote{\cite[ch. 5]{Quine1986}. For discussion of higher-order logic and Quine's criticism of it, see \cite{Shapiro2001}.} Another consequence of Quine's influence was the return of a fairly strong form of realism, like that of Russell, to philosophical logic. Though Quine did not exercise any major influence directly on the concept of logical consequence, his understanding of quantification as ranging over the entire universe of entities, along with the ontological use he put the quantifiers toward, ensured the domain of quantification continued to be held invariant in philosophical appropriations of mathematical logic for some time \cite[31-32]{Quine1948} \cite{Eder2016} \cite{Lewis1968}, even while domain variation garnered acceptance among those working more directly on mathematical logic \cite{Henkin1949} \cite{Kemeny1948} \cite{Kemeny1956} \cite{Tarski1953a}.
	
	Quine influenced the understanding of logical consequence in a further way through his attack on the concept of analytic truth \cite{Quine1951} \cite{Quine1960a}.Both the earlier approach of Carnap and the proof-theoretic approach inspired by Gentzen base their notions of logical consequence on the notion of analyticity: For Carnap, a sentence $A$ follows from a premise set $\Gamma$ provided it follows strictly from the meaning of the logical terms contained in the sentences of $\Gamma$. In the limit case where $\Gamma$ is empty, Carnap assumed $A$ is a logical truth just in case it is true in virtue of the meaning of its logical terms. Likewise, Gentzen held the I-rules for the various propositional connectives were sound because they gave the meaning of the connective introduced in the conclusion. Now, if the notion of something holding in terms of meaning turns out to be imprecise, as Quine charged, then a notion of consequence presupposing it would be similarly inexact. Quine's attack on analyticity thereby helped bolster the dominance of model-theoretic approaches, where the fundamental notion is the extensional one of satisfaction, rather than that of meaning.
	
	The next important development, implicit in the development of Kripke semantics for modal logic \cite{Kripke1963a} \cite{Kripke1965}, was the division \textit{}of logical consequence into local and global varieties. In contemporary modal logic, a sentence $K$ is said to follow \textit{locally} from a premise set $\Gamma$  for a class of frames $C$ iff, for every frame in $C$, for every model on that frame, every world in that model modelling all members of $\Gamma$ also models $K$; while $K$ is said to follow \textit{globally} from $\Gamma$ iff, for every frame in $C$, for every model on that frame where all members of $\Gamma$ are \textit{valid} - i.e. where all members of $\Gamma$ are modeled by \textit{every} world in the model - $K$ is also valid.\footnote{See \cite[21-23]{Fitting1998} \cite[31-32]{Blackburn2001}. This does not mean no distinction was made between rules that preserve truth and those preserving \textit{validity}, such as universal generalization in quantified systems and necessitation in modal logics, prior to the development of modal logic. But it does mean the formulation of different consequence relations in terms of local and global models was not yet present in this more basic point.} Unsurprisingly, this division brought with it the question of which notion, if either, expresses the genuine notion of following logically.
	
	The latter half of the 20th century through to today has witnessed the proliferation of a vast number of non-classical logics; of domain specific extensions of classical logic, including deontic logics, temporal logics, and epistemic logics; and even of logics with no intended `logical' application, many of which are developed for use in computer science. Each of these developments brings with it new questions. The development of domain-specific logics poses the question of whether these - given once widespread views about the universality of logic - should be genuinely called \textit{logics}. Individually, each non-classical logic brings with it the question of whether it, rather than classical logic, determines the correct class of formal consequences;  collectively, this vast plurality prompts the question of whether the immediately preceding question is even a sensible one.\footnote{This question is taken up in the debate between logical \textit{pluralists}, on the one hand, and logical \textit{monists}, on the other. See \cite{BeallRestall2006} \cite{Griffiths2013}.}
	
	\subsubsection{Developments in the proof-theoretic tradition}
	At around the same time Tarski was developing his semantic account of formal consequence, Gerhard Gentzen and Stanis\l{}aw Ja\'{s}kowski independently formulated the first systems of natural deduction. While Ja\'{s}kowski apparently did not apply this discovery to a consideration of consequence, Gentzen's formulation was accompanied by the claim that
	\begin{quote}
		The introductions represent, as it were, the `definitions' of the symbols concerned, and the eliminations are no more, in the final analysis, than the consequences of these definitions \cite[80]{Gentzen1934Eng}.
	\end{quote}
	
	The approach to connective meaning present in this well-known quote thoroughly differs from that found in Tarski. In Gentzen's remark, the meaning of the logical symbols does not transcend their syntax, but is given immanently in the rules governing their use in the proof system. For Gentzen, it is the introduction rule that gives a connective its meaning, though alternative approaches, where the elimination rule is prioritized, have also been proposed \cite[186]{Schroeder-Heister2014}. 
	
	The broader principle invoked in Gentzen's approach is that meaning is given by \textit{use}. On the supposition that correct use is a kind of rule following, this principle is itself usually equated with the idea that the meaning of a term is determined by rules. Both ideas are indebted to the philosophy of the later Wittgenstein, and probably achieved their widest audience in the work of Dummett. The claim in philosophy of language that meaning is determined by inferential role is the central tenet of \textit{inferentialism}, and its advocates are called \textit{inferentialists}. \textit{Logical inferentialism} is the claim in philosophy of logic that the meaning of \textit{logical constants} is determined by the rules governing them in some formal proof system. \textit{Proof-Theoretic Semantics} is a project attempting to give the meaning of the connectives entirely within the language of proof-theory, and thus without recourse to model-theory.
	
	Later inferentialists would build up an account of following formally from Gentzen's proof-theoretic account of meaning, just as Tarski's approach does for the semantic account.\footnote{\cite[159]{Prawitz1985}. \cite[366-376]{Franks2010} suggests that already in \cite{Gentzen1934}, Gentzen regarded his proof of the admissibility of cut elimination as a proof of the completeness of the analytic fragment of his proof systems - i.e. the connective rules - with respect to the synthetic notion of following.} In the wake of Gentzen and Ja\'{s}kowski's development of natural deduction, two prominent proof-theoretic approaches to logical consequence have arisen. One, originating with Paul Lorenzen and championed today in the work of Peter Schroeder-Heister, regards logical consequence as a relation between rules \cite{Lorenzen1955} \cite{Schroeder-Heister1984} \cite{Schroeder-Heister2006} \cite{Schroeder-Heister2014}. The other, present in the work of Prawitz, holds a sentence $A$ is a logical consequence of a set of sentences $\Gamma$ exactly when there is a logically valid argument for $A$ from $\Gamma$ \cite{Prawitz1974} \cite{Prawitz1985}.
	
	In the first of these two approaches, the meaning of a connective is straightforwardly identified with a rule.\footnote{In the following, we follow the exposition of \cite[155-159]{Prawitz1985}.} In general, \[A_{1},...,A_{m} \longrightarrow_{x_{1}...x_{n}} B\] is taken to mean that for $m, n \geq 0$, there is a rule to move to $B^{\sigma}$ from $A^{\sigma}_{1},..., A^{\sigma}_{m}$, where $\sigma$ is any substitution for free occurrences of variables $x_1, ... , x_{n}$, taking standard precautions to preclude conflict between free and bound variables.
	
	Since each formula (including atomic formulas) is identified with a rule, a corresponding notion of a consequence $\Gamma \stackrel{k}{\Rightarrow} A$ in $k$ steps can be defined inductively as follows: 
	\begin{enumerate}
		\item For atomic $A$:
		\begin{enumerate}
			\item $\Gamma \stackrel{k}{\Rightarrow} A$ iff $A \in \Gamma$; or
			\item there is a rule of the form $(A_{1}, ... , A_{m} \longrightarrow_{x_{1}, ... , x_{n}} B)$ in $\Gamma$ and a substitution $\sigma$ such that for each $i\leq m$, $\Gamma \stackrel{k'}{\Rightarrow} A^{\sigma}_{i}$ for some $k' < k$, and $\Gamma, B^{\sigma}\stackrel{k'}{\Rightarrow} A$ for some $k'< k$.
		\end{enumerate}
		\item For nonatomic $A$ of the form $A_{1},...,A_{m}\longrightarrow_{x_{1},...,x_{n}} B$
		\begin{enumerate}
			\item$\Gamma \stackrel{k}{\Rightarrow} A$ iff $\Gamma, A_{1}',...,A_{m}' \stackrel{k}{\Rightarrow} B'$, where $A_{i}'$, $B'$ are exactly like $A_{i}, B$ except perhaps containing free $y_{1},...y_{n}$ (not occurring free in $\Gamma$) in place of $x_{1},...,x_{n}$.\footnote{\cite[156]{Prawitz1985}.}
		\end{enumerate}
	\end{enumerate}
	
	In a sufficiently expressive language, the meaning of different syntactic strings in propositional, first order, and higher-order logic may be identified with different rules. For instance, $A\vee B$ can be identified with the rule \[(A\rightarrow X), (B\rightarrow X) \rightarrow_{X} X\]. 
	
	The exact details outlined above need not concern us too much. The basic idea is that in this framework, $B$ is a logical consequence of $A$ just in case $A* \Rightarrow B*$, where $A*$ and $B*$ are translations of $A$ and $B$ into rule form.
	
	The second of the above approaches, by contrast, does not  \textit{identify} formulas with rules, but advocates the weaker claim that the meaning of a connective is \textit{given} by its rules. This claim has been interpreted in a number of ways. In some cases, it is the meaning of the connective that is said to be determined; in others, sentences in which the connective occurs.\footnote{For instance, \cite{Read2010} makes use of the first formulation, while \cite[162]{Prawitz1985} uses the second. The idea that it is the \textit{sentences} that are given meaning is based on a claim attributed to Frege, that words only have their meaning in the context of a sentence. See \cite{Frege1948}. \cite[308]{Davidson1967}.} In some cases, the meaning of the connective [sentence] is thought to be determined fully; in others, only a criterion for meaningfulness is given. When pairs of introduction and elimination rules meet the requirement for meaningfulness, the rules are said to be in harmony, and the system in which they occur is said to be harmonious.
	
	The simplest and strongest account of connective meaning involves the idea that a language is meaningful provided it is \textit{conservative}. More formally, a system $S'$ for a language $L'$ is conservative with respect to a system $S$ for a language $L$ provided that if a formula $A$ of $L$ is provable in $S'$, then $A$ is already provable in $S$. For instance, let $L$ be the language for the implicational fragment of classical logic $S$, and $L'$ the result of adding classical negation to $L$. Here, conservativity says adding negation to $L$ shouldn't allow us to prove new formulas that do not themselves involve negation, i.e. any formula involving only implications should be provable without making use of negation. In point of fact, $L'$ is \textit{not} conservative with respect to $L$, since Pierce's law, $((A\rightarrow B)\rightarrow A) \rightarrow A$, can be proved in $L'$ but not in $L$. Conservativity was proposed as a criterion for connective meaning in \cite{Belnap1962}, and later advocated by \cite{Dummett1991}, where the condition is called 'total harmony'. Because classical negation is not harmonious with respect to the other classical connectives, it is sometimes denied the status of a a genuine logical connective; and likewise because conservativity fails in classical logic, it is denied the status of a genuine logic.
	
	The above account would suffice to rule out certain consequence relations as genuine species of logical consequence. It does not, however, give us a direct, positive proof-theoretic account of what it is for something to follow logically. For this, we turn to two additional criteria for connective meaning: i) normalization, and ii) inversion. 
	
	Harmony is a relation obtaining between introduction and elimination rules for a connective on account of which the connective is said to be meaningful. Total harmony is the requirement that each connective $C$ of a proof system $S'$ be conservative with respect to the fragment of $S$ resulting from eliminating $C$ from the language $L$ for $S$. A different criterion, which Dummett calls `intrinsic harmony', insists that proofs be \textit{normalizable}. Normalization is a procedure performed on proofs, while inversion is a procedure that, given an introduction [elimination] rule, yields a corresponding elimination [introduction] rule for the same connective. 
	
	A proof $A \rightarrow B$ is \textit{normalizable} when its \textit{maximal formulae} - formulae occurring both as the conclusion of an I-rule and a major premise of an E-rule - are all eliminable. A proof resulting from the elimination of maximal formula is said to be in \textit{normal form}, and is sometimes called a \textit{normal proof}. In the majority of cases, a proof will be normalizable just when there is an inversion procedure for obtaining the E-rule for the connectives involved in it from their I-rules. There are cases, most of which involve the introduction of paradoxical connectives, where inversion does not guarantee normalization \cite{Read2010}. For Prawitz, the inversion procedure, what he calls `the way in which the elimination rules are justified by the introduction rules', is `what makes possible normalizations of proofs in natural deduction' \cite[160]{Prawitz1985}.
	
	In Prawitz's proof-theoretical account of logical consequence, paradoxical connectives are left aside. For the moment, we do the same. For further simplication, we only detail the propositional case. For Prawitz, `a sentence $A$ is said to be a \textit{logical consequence} of a finite set $\Gamma$ of sentences when there exists a logically valid argument for $A$ from $\Gamma$' \cite[166]{Prawitz1985}. Let's break this down. 
	
	For Prawitz, an argument is `an arbitrary collection of linked inferences', where one sentence is asserted on the basis of other sentences \cite[166]{Prawitz1985}. From here, we proceed in a manner analogous to the treatment of variables in quantification theory, with assumptions taking the place of variables, inferences the place of quantifiers, and arguments the place of formulas. An assumption occurring in an argument may be \textit{bound} or \textit{free}. When an inference discharges the dependency of an argument on an assumption, it is said to bind the assumption; and an assumption is free iff it is not bound, i.e. not discharged. An argument is open if it contains a free assumption, and closed if all its assumptions are bound.
	
	Among arguments, certain ones are singled out as \textit{canonical} arguments. The intuitive idea behind a canonical argument is that it is self-justifying, because it determines what it means for a sentence of that form to hold. For Prawitz, the archtypal examples of canonical arguments are the I-rules for the different connectives in a natural deduction system. He writes:
	\begin{quote}
		if somebody asks why the rule for $\wedge$-introduction [...] is a correct inference rule, one can answer only that this is just part of the meaning of conjunction: the meaning is determined partly by laying down that a conjunction is proved by proving both conjuncts, and partly by the understanding that a proof of conjunction could always be given in that way \cite[163]{Prawitz1985}. 
	\end{quote}
	While I-rules are regarded as laying down what it means for a sentence of a given form to be valid, E-rules are treated by Prawitz as \textit{justifying procedures}. More specifically, they provide a way of transforming any non-canonical argument into a canonical one.\footnote{Prawitz sees this claim as a generalization of Gentzen's proof that arguments of a Natural Deduction system can always be given in normal form.}
	
	An open argument is valid if its closure is valid. The validity of a closed argument is defined inductively as follows: 
	\begin{enumerate}
		\item Every closed argument in canonical form whose immediate subarguments are valid is valid.
		\item If an argument $D$ is not in canonical form, but there is a set of justifying operations $J$ that, when successively applied to $D$, transforms it into an argument where the previous condition holds.
	\end{enumerate}
	
	Lastly, an argument is \textit{logically valid} provided `it is valid relative to each system of canonical arguments for atomic formulas' \cite[165]{Prawitz1985}.
	
	So in its expanded form, Prawitz's account of logical consequence comes to the following: a sentence $A$ is a logical consequence of $\Gamma$ provided that in every system of canonical arguments for atomic formulas, i) if $\Gamma / A$ is open, its closure is valid; ii) $\Gamma / A$ is itself an argument in canonical form; or iii) if $\Gamma / A$ is not in canonical form, there is a justifying procedure $J$ whereby the argument may be transformed into a canonical one.
	
	\subsection{Common elements in the above accounts}
	The contemporary situation brings with it questions about the necessity of formal consequence, the correct class of formal consequences, the domain of formal consequence, and the purported universality of formal consequence. In light of this, can we say much about what has remained common in the way the concept of logical or formal consequence has functioned from prior to Tarski to the present?
	
	Yes. A surprising degree of unity underlies the developments and diversity outlined above. Partisans of all of the above accounts typically presuppose 1) that for a consequence to be logical and for it to be formal amount to the same thing.\footnote{For an exception, see \cite{Read1994}.} 2) All of the above accounts accord a place of prominence to substitutionality, though in different ways. 2a) In the model-theoretic approach, valid consequences are determined by varying the interpretation of the non-logical components of a formalized language, or otherwise by varying those components themselves.\footnote{This is strictly true for the accounts of consequence found in \cite{Tarski2002} and presupposed in the metaphysical projects of \cite{Quine1948} and \cite{Lewis1968}. Later model-theoretic approaches take variability a step further, by allowing variations on the size and elements in the domain, on the set of possible worlds, etc. But when this is done, the invariance of consequence under permutation of non-logical terms becomes only a necessary condition for its holding formally.
		
		The sense of `substitutional' used above is wider than that used to distinguish substitutional from objectual semantics for first-order languages. A substitutional semantics in the more restricted sense is one on which the truth value of its quantified formulae in a model is determined by the truth value of instances of those formulae wherein the formerly bound variables have been replaced by new terms. An objectual interpretation, by contrast, is one on which it is not the terms, but the objects assigned to the variables that are varied. Typically, an objectual semantics is preferred on the grounds that substitutional semantics is not consistent with the intent to quantify over superdenumerable domains, e.g. the real numbers. But from a purely mathematical standpoint, the class of substitutional models can be represented as a subset of the objectual ones, i.e. those where the domain of the model is just the set of terms in the language. See \cite[ch. 14]{Garson2013}.} 2b) in the proof-theoretic approaches surveyed, substitution shows up in a less explicit manner, in the assumption that formally valid consequences hold schematically.\footnote{Cf. Dutilh Novaes (2011). Both Prawitz and Schroeder-Heister make this more explicit than usual: Schroeder-Heister by his use of propositional quantification in his interpretation of formulas as rules; Prawitz doubly so, by his distinction between open and closed arguments, and by his restricting logically valid arguments to those that hold in \textit{every} system of canonical arguments.} 3) In all model-theoretic accounts, substitutionality is taken not merely for a condition on consequence, but rather defines \textit{what it is to be} a formal consequence.\footnote{Cf. \cite[66]{Etchemendy1988}: \begin{quote}
			...as far as extensional adequacy goes, there are a multitude of equally correct (or equally incorrect) definitions of first-order consequence: when we specify any one of the many equivalent proof procedures for first-order languages, we have defined the consequence relation as adequately as when we define the relation model-theoretically. But from among these coextensive definitions, the model-theoretic account is account is typically afforded a special status, a status most clearly reflected in soundness and completeness theorems.
		\end{quote}} 
		And in the Tarski-Quine-Lewis tradition, one finds the assumptions that 4) that precisely those notions which are required to be invariant under all interpretations are the logical notions of a given language; 5) that a consequence is valid \textit{in virtue of} these notions, and it is on account of these that a consequence has its logical form; 6) that a logic is individuated by its class of logical notions; and 7) that, accordingly, without a principled and sharp demarcation criterion for discriminating between the logical and non-logical components of a formal language, we also lack an adequate understanding of the scope and nature of logic \cite{MacFarlane2009}.
		
		To get a better grasp on some of the above points, it is worth reflecting on what formality in logic is most likely to be contrasted with. On the one hand, the formal is said to be the opposite of the \textit{in}formal. In this sense, formality is typically associated with rigor on account of its use symbolization, itself in the service of obscuring the meaning of the matters to which it is applied for the sake of making these formulae more easily or even effectively calculable \cite[321-325]{DutilhNovaes2011}. And so the spirit of informal logic would be typified by an approach to logic working in or otherwise heavily reliant on natural (as opposed to formalized) language, and one making use of the meanings of the terms it treats in determining what follows from them. Such an approach is found, for instance, in the ordinary language tradition of Ryle.
		
		On the other hand, the formal is contrasted with the \textit{material}. In this hylomorphic contrast lifted from the framework of Aristotelian physics, form and matter are constitutive components of every material being (1); form is that which remains invariant in a material being throughout its existence (2, 3, 4); it makes a thing to be what it is, thereby determining its definition and quiddity (3, 5); and on some medieval accounts, serves as a principle of individuation (item 6).
		
		Underlying the multitude of different positions and debates mentioned in the previous section is a common core of thinking about logic lifted from this hylomorphic framework, albeit manifested in different ways. This is surprising on several accounts: first, because logic is often thought to be formal precisely inasmuch as it demurs from either any particular content or metaphysical assumptions; second, because even among metaphysically minded logicians (or logically minded metaphysicians), \textit{any} kind of hylomorphism remains a distinct minority opinion.
		
		The most specific kind of hylomorphism present in the points outlined above - that of Tarski's early account - is what Catarina Dutilh Novaes, following Kathrin Koslicki, calls \textit{mereological} hylomorphism \cite{DutilhNovaes2012b} \cite{Koslicki2006}. Mereological hylomorphism is characterized by the contention not merely that wholes are compounds of form and matter, but also that form and matter are themselves distinct integral parts of the hylomorphic compound. This is reflected in the partition of linguistic signs presupposed in Tarski's notion of formal consequence, where one part - the logical constants  - corresponds to the form, and the rest to the matter.
		
		\section[Buridan's concept of formal consequence]{John Buridan's concept of formal consequence}
		The first known account of formal consequence in the western tradition directly defined in terms of a substitutional criterion is that of John Buridan, the 14th century Master of Arts at the University of Paris. Buridan was not the first of the medievals to distinguish between formal and material consequence - the distinction is first made explicit by Ockham, and implicit in Duns Scotus, Simon of Faversham, and others - but Buridan was the first to distinguish formal and material consequences by varying the categorematic terms of an argument.\footnote{Note that for Buridan, in contrast with today's practice, the \textit{terms themselves} are varied, rather than their interpretations. For instance, he says `A man runs; therefore, an animal runs' is not a valid formal consequence, because `A horse walks, therefore a tree walks' is not \cite[TC 1.4.3]{Buridan2015}.} Buridan's way of distinguishing material from formal consequences was especially influential on the European continent, having been adopted by Marsilius of Inghen, Albert of Saxony, and others \cite{DutilhNovaes2012a}. According to Buridan, 
		
		\begin{quote}
			A consequence is called formal if it is valid in all terms retaining a similar form. Or, if you want to put it explicitly, a formal consequence is one where every proposition similar in form that might be formed would be a good consequence [..]. A material consequence, however, is one where not every proposition similar in form would be a good consequence, or, as it is commonly put, which does not hold in all terms retaining the same form.\footnote{\cite[I.4, p. 68]{Buridan2015}: 
				
				\begin{quote}
					Consequentia `formalis' vocatur quae in omnibus terminis valet retenta forma consimili. Vel si vis expresse loqui de vi sermonis, consequentia formalis est cui omnis propositio similis in forma quae formaretur esset bona consequentia [...] Sed consequentia materialis est cui non omnis propositio consimilis in forma esset bona consequentia, vel, sicut communiter dicitur, quae non tenet in omnibus terminis forma consimili retenta.
				\end{quote}}
				
			\end{quote}
			
			There are some important differences between the way formal consequence is understood by Buridan, and the way it is understood today - to name two, the basic units of Buridan's consequences are written or spoken sentences, and therefore his semantics is token rather than type-based \cite{Klima2004} \cite{DutilhNovaes2005}; and Buridan doesn't assume a material consequence is thereby not a logical one.\footnote{Much of the renaissance of Buridan scholarship in the past half century has been motivated by \textit{prima facie} similarities between Buridan's treatment of various logical topics and contemporary treatments of what are recognizably the same topics and questions. Cf. \cite{Moody1952} \cite{Bochenski1956} \cite{Kretzmann1982} \cite{Parsons2014}.}
			
			But whatever one makes of these lesser differences, there is one difference that makes studying Buridan and his contemporaries an especially fruitful endeavor: the medieval application of hylomorphic language to consequences could not but be a \textit{conscious} one, taking place at the height of critical engagement with both Aristotle's logic and his physics and metaphysics; whereas the contemporary appropriation of hylomorphic language has been by and large uncritical and at times unaware of this appropriation.\footnote{Important exceptions include \cite{Read1994} \cite{Read1995} \cite{MacFarlane2000} \cite{DutilhNovaes2011} \cite{DutilhNovaes2012a} \cite{DutilhNovaes2012b} \cite{DutilhNovaes2012c}.} If, at times, medieval treatments of consequence appear less sophisticated than their contemporary analogues, they're also somewhat less liable to the distractions that accompany the development and long use of a technical vocabulary, and thereby often closer to the matters themselves under discussion.\footnote{This is an application of a broader point frequently ignored in both historical and systematic discussions today: our later standpoint on questions of philosophical importance is not wholly an advantageous one, inasmuch as the development of any body of knowledge brings with it a certain forgetfulness of its origins. To take an especially clear example, the vast proliferation of logics in the past century, while it has brought us a great many proofs, has not brought us a step closer to an understanding of what logic is or of what it is about. Aristotle, whatever one may think of his analytical and topical works, at least had some sense for what he was doing. Our current state regarding the sense of these questions, by contrast, is probably more bewildered than it has ever been.}
			
			
			\section{Overview}
			The aim of this study, then, is to uncover the meanings implicit in our use of the notion of formal consequence by peeling back the layers of meaning imposed at the time when `the main precursor of the modern concept of logical consequence' was first formulated \cite{DutilhNovaes2012a}. The general plan of the work is to begin with Buridan's notion of formal consequence, and from there to move backwards in successive stages to its historically antecedent enabling conditions. 
			
			The questions surrounding the genesis of Buridan's notion, though not all answered, have at least reached a point where they are easily formulable and relatively tractable. The main questions are as follows: 
			\begin{enumerate}
				\item What is Buridan's account?
				\item How does Buridan's account relate to that of Ockham, the first to explicitly mention a distinction between formal and material consequence?
				%\item How does Buridan's account differ from that of Tarski, and from those model-theoretic accounts descended from him?
				\item How does the division of consequences into formal and material relate back to the division between natural and accidental consequences, i.e. to the division it seems to have replaced?
			\end{enumerate}
			There are, of course, more fine-grained questions ensconced within those mentioned, as well as questions that may be asked on either chronological side of these. One may ask, for instance, how the notion of formal consequence is developed by Buridan's followers, or about the development of earlier divisions of consequences. But answering the questions enumerated would yield a philosophically illuminating and relatively self-contained answer to the question of where formal consequence actually came from.
			
			The immediately following chapter provides a more in-depth introduction to Buridan's concept of formal consequence in itself. I begin by reviewing classical formal consequence, then its differences from the account of formal consequence found in Tarski. This is followed by an analysis of Buridan's own approach, examining Buridan's definition and division of consequence into formal and material. The final part compares Buridan's account to Tarski's and its successors in current model-theory. 
			
			Chapter three compares the account of consequence found in Buridan to that of Pseudo-Scotus. Recently, Lagerlund and Read have both held that Pseudo-Scotus' treatment of formal consequence must antedate that of Buridan \cite{Lagerlund2000} \cite{Read2015}. Here, I show this is not the case. A detailed examination of parallels between Buridan's \textit{Tractatus de consequentiis} and the relevant texts from Pseudo-Scotus' \textit{Questions on the Prior Analytics} shows the Scotus text builds on that found in Buridan; while Buridan's own criterion for valid consequence was the likely target of the \textit{Pseudo-Scotus} paradox, a paradox first found in Pseudo-Scotus' text, resembling Curry's paradox today.
			
			Chapter four investigates modal formal consequences in the account of William of Ockham. Ockham distinguishes between two readings of modal propositions: one called `composite'; the other, `divided'. Today, treatments of Ockham's distinction assimilate it to one between wide and narrow-scope modality in first-order classical modal logic. Doing so, however, renders certain consequences Ockham countenances invalid. I provide a formal reconstruction of Ockham's account which validates the arguments Ockham uses in his text, and gives a full account of the formal entailments and oppositions between two term categorical modal propositions according to their quality, quantity, and range of quantification.
			
			%Chapter four compares Buridan's account of formal and material consequence to that of Ockham. The first part of the chapter provides a systematic comparison between the two accounts, while the second part investigates the question of influence. Recent literature has been apt to distinguish Ockham's account from Buridan's - and indeed, British from Continental medieval approaches to formal and material consequence more generally - by saying that while the tradition on the continent formulated the distinction between formal and material consequences substitutionally, the British tradition formulated the distinction in epistemic terms.\footnote{See, for instance, Dutilh Novaes 2012a.}. I show that in the case of Ockham, this isn't quite right. Rather, the formality of Ockham's formal consequence essentially consists in its holding by virtue of an extrinsic rule normatively binding on the thought patterns of actual reasoners. In this way, Ockham's account of formal consequence anticipates both the rules-based accounts of proof-theoretic semantics and the Kantian association of logic with laws of thought. The second part answers the question of whether either the language or the content of Buridan's distinction is in fact derived from Ockham. In short, I show that though Buridan had read Ockham by the time he composed his commentary on the Aristotle's \textit{On Sophistical Refutations}, nothing in the content of Buridan's notion of formal consequence in the \textit{TC} gives us reason to believe he had read Ockham prior to that point. Given that the notion of formal consequence had existed at Paris prior to Ockham's writing the \textit{Summa Logicae}; and given the fairly deep differences between their accounts, it seems more likely than not that Buridan's development of the notion and adoption of the distinction between formal and material consequences is largely an independent development, at best indirectly related to Ockham's distinction.
			
			Chapter five introduces the account of consequences found in Walter Burley's later \textit{De Puritate Artis Logicae (On the Purity of the Art of Logic)}. Burley is perhaps best known for his `realism' in metaphysics; and in part because of this, his own account of consequence has been understudied, and its relation to and influence on nominalists like Buridan has not been thoroughly considered. The later version of Burley's \textit{De Puritate}\footnote{There is also an earlier version, sometimes called the \textit{tractatus brevior}. Though sharing some material with its later counterpart, the earlier treatise is not an abbreviation of the later one, and includes material not included in the later treatise.} was completed while Burley was at Paris, and seems to have been widely read and circulated there. However, by the time the treatise appeared, Burley had a wealth of material from commentaries and short tracts stretching back to his time at Oxford, and Burley's treatise was itself conceived in part as a response to Ockham. Though Burley makes use of a distinction between formal and material consequence, the distinction does not hold the prominence it does in Buridan's account: in its place, we find a distinction between natural and accidental consequence. This chapter shows the relation of Burley's treatise to the earliest work on consequences, and explains the relation of Burley's division of consequences to that which followed it.
			
			
			%The fifth chapter considers a different influence on the development of theories of consequence: 14th century accounts of hylomorphic composition in commentaries on Aristotle's \textit{Physics}, \textit{Metaphysics}, and shorter physical treatises. Here, I show that Buridan's \textit{logical} hylomorphism reduplicates the peculiarities found in his \textit{physical} hylomorphism: in particular, Buridan's physical hylomorphism is mereological: for Buridan, form is a proper, integral part of a composite substance. Furthermore, Buridan himself assimilates the distinction between form and matter to one between substance and accident, maintaining that the matter of a material substance is united to its form as an accident to a substance. This assimilation helps explain how the distinction between natural and accidental consequences is assimilated to, and ultimately supplanted by, that between formal and material consequences. In short, while the mereological hylomorphism of Buridan's physics need not have necessitated his physical hylomorphism, it did help facilitate it.
			
			%The penultimate chapter examines three early tracts on consequences - two anonymous, one by Walter Burley, all of which are translated in appendices to this dissertation. The chapter vindicates a thesis advocated by Eleonore Stump \cite{Stump1989}, and contested by Niels J. Green-Pedersen \cite{Green-Pedersen1984}: that the earliest treatises on consequences have their main source in treatises on \textit{topics}, particularly in commentaries on Aristotle's \textit{Topics} and Boethius' \textit{De Topicis Differentiis}. However, considerations pertaining to supposition also loom large in these earlier treatises, particularly in the way the validity of different consequences is affected by problems of existential import.
			
			The final chapter takes a synoptic view of the results detailed in the previous chapters, returning to their import for the ways in which logic is said to be formal today.