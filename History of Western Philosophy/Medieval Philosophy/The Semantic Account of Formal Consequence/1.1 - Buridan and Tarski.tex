\documentclass[]{article}

%opening
\title{Formal consequence, from Alfred Tarski back to John Buridan}
\author{}

\begin{document}

\maketitle

\section{Introduction}
The resemblance between Buridan's and Tarski's theories of formal consequence has long been remarked upon, 
so much so that it accelerated the rediscovery of Buridan as a major medieval figure in the latter half of the twentieth century.\footnote{See \cite{Moody1952} \cite{Kneale1962} \cite{Dumitriu1974} \cite{DutilhNovaes2012a} \cite{DutilhNovaes2012c} \cite{Parsons2014}, and the editor introductions to \cite{BuridanTC}, \cite{Kretzmann1982} and \cite{King1985}.} 
But while long noticed, 
it has not yet been subjected to sustained general analysis.

In this article, 
I provide just such an analysis. 
I begin by reviewing today's understanding of classical consequence, 
highlighting its differences from the account Tarski provides in \cite{Tarski2002}. 
Following this, 
I introduce Buridan's account of formal consequence, 
detailing its philosophical underpinnings, 
then its content. 
This prepares the ground for Buridan and Tarski's respective accounts of following formally to be compared directly.
\section{From classical consequence back to Tarski}
\subsection{Classical consequence today}
\subsubsection{Classical syntax}
Classical consequence today is constructed as follows. 
One begins with an artificial language $L = (Trm, Pred, Con, F)$. 
$Trm = N \cup Var$ is a collection of \textit{terms}, 
itself the union of a set of \textit{names} $N = \{a, b, c, ...\}$, 
and \textit{variables} $Var = \{x, y, z, w, x'...\}$. 
$Pred$ is a set of n-ary relation symbols $\{P^{1}, Q^{1}, R^{1},..., P^{2},..., P^{n}\}$.\footnote{Here, the superscript indicates the \textit{arity} of the relation symbol, 
	i.e. the number of arguments it takes. 
	Intuitively, 
	a relation symbol of arity one is a one-place predicate, 
	e.g. `is Red'; 
	of arity two, 
	a two-place relation, 
	e.g. `is greater than'; 
	of arity three, 
	a three-place relation, 
	e.g. `is the sum of', 
	and so forth. 
	In practice, the superscript is dropped, 
	and the arity of a predicate is determined by context.} 
$Con = \{\neg, \supset, \vee, \wedge, \equiv\, \exists, \forall, (, )\}$ is our collection of logical constants.
The two-place identity predicate $=$ may also be classified as a constant, 
so that $Con \cap Pred = \{=\}$. 
The class of formulas $F$ is then determined recursively as follows:
\begin{itemize}
\item[1] If $t_{1} ... t_{n}$ are terms, 
and $P^{n}$ is an n-ary relation symbol, 
then $P^{n}(t_{1} ... t_{n})$ is a formula. 
These formulas are called \textit{atomic formulas}. 
Any variables among the terms of $P^{n}(t_{1} ... t_{n})$ are said to be \textit{unbound}.
\item[2] If $A \in F$, then $\neg A \in F$. The unbound variables of $\neg A$ are the same as those of $A$.
\item[3] If $A, B$ are formulae, then so are $(A \supset B)$, $(A \vee B)$, $(A \wedge B)$, and $(A \equiv B)$, their unbound variables being those of $A, B$.
\item[2] If $A \in F$, and $v \in Var$, then $\forall v A$, $\exists v A$ are formulae. Here, the quantifiers $\forall v$ and $\exists v$ are said to \textit{bind} the free occurrences of $v$ in $A$. A formula all of whose variables are bound is called a \textit{sentence}.
\item[4] Nothing else is a formula.
\end{itemize}
In practice, outermost parentheses and those bracketing terms are dropped, formulae involving the identity predicate are written $t_{1} = t_{2}$ rather than $=(t_{1}, t_{2})$, and $\neg=(t_{1}, t_{2})$ is written as $t_{1} \ne t_{2}$.

\subsubsection{Classical semantics}
After giving conditions for what constitutes a formula, conditions are provided for determining when they are true or false. To do this, one defines a model $M = (D, I)$ as a pair of a \textit{domain}, $D$, and an \textit{interpretation} $I$. $D$ is  a collection of objects: cats and dogs, numbers, members of the Medici family, or whatever else one likes. The domain of a model may be finite, countably infinite, or even uncountably infinite, but is usually not allowed to be empty. The interpretation function $I$ then assigns: each name $a$ to an element in the domain $D$; and each n-ary relation symbol $R^{n}$ to a subset of $D^{n}$;\footnote{I.e. the nth Cartesian product of the domain, the result of multiplying the domain $n$ times with itself.}. Besides interpretations, one also has \textit{valuations} $\{v, v' ...\}$ on $M$, each of which assigns values in $D$ to all the variables of the language $L$. Valuations are normally not considered part of a model, since the truth or falsity of a \textit{sentence} relies on no one valuation in particular, though the determination of the truth-value of various \textit{formulae} is partially determined by valuations. One thus says that a formula $A$ is true in $I$ under a valuation $v$. For notational convenience, we let $(v \star I)$ be the operation such that $v \star I$ agrees with $v$ on the assignment of variables, and with $I$ on the assignment of terms, and write $(v \star I)(t_{1}, ...t_{n})$ for $((v \star I)(t_{1}), ... (v \star I)(t_{n}))$. Lastly, we call a valuation $v'$ an \textit{$x$-variant} (\textit{$y$-variant}, etc.) of a valuation $v$ iff $v'$ agrees with $v$ on all variable assignments except perhaps $x$. The truth value of different formulae in a model $M$ - i.e. \textit{truth in a model} - is then recursively determined as follows:

\begin{enumerate}
\item For atomic formulae of arity $n$, $(v \star I)(Rt_{1}...t_{n}) = T$ iff $(v \star I)(t_{1}, ... t_{n}) \in I(R)$
\item $(v \star I)(\neg\phi) = T$ iff $(v \star I)(\phi) = F$
\item $(v \star I)(\phi \wedge \psi) = T$ iff $(v \star I)(\phi) = (v \star I)(\psi) = T$
\item $(v \star I)(\phi \vee \psi) = T$ iff $(v \star I)(\phi) = T$ or $(v \star I)(\psi) = T$
\item $(v \star I)(\phi \supset \psi) = T$ iff $(v \star I)(\phi) = F$ or $(v \star I)(\psi) = T$
\item $(v \star I)(\phi \equiv \psi$ = T iff $(v \star I)(\phi) = (v \star I)(\psi)$
\item $(v \star I)(\forall x \phi) = T$ iff, for every $x$-variant $v'$ of $v$, $(v' \star I)(\phi) = T$
\item $(v \star I)(\exists x \phi) = T$ iff, for some $x$-variant $v'$ of $v$, $(v' \star I)(\phi) = T$
\end{enumerate}

From here, a sentence $\phi$ is \textit{satisfiable} if it is made true on some model $M$. When this happens, $M$ is said to be a \textit{model} of $\phi$. Next, let $\Gamma$ denote a (finite or infinite) string of sentences $\phi, \psi, ...$. We say $\Gamma$ is satisfiable iff there is some model $M$ on which every sentences in $\Gamma$ is satisfiable. Similarly when this occurs, $M$ is said to be a model of $\Gamma$. Lastly, a sentence $\phi$ is said to be a logical consequence of a sentence $\Gamma$, written $\Gamma \models \phi$, iff every model of $\Gamma$ is a model of $\phi$.
\subsection{Tarskian consequence}
Tarskian logical consequence is based on a \textit{permutation-invariance} criterion for logicality: $\Gamma \models \phi$ precisely when there is no uniform substitution on  non-logical constants in $\Gamma, \phi$ that models $\Gamma$ but not $\phi$. And in his post-WWII period, Tarski embraced many additional aspects of the received approach to classical consequence - for instance, he made increasing use of set theory as a metatheory, and rejected higher-order logic in favor of first-order logic \cite{Tarski1987} \cite[372]{Corcoran2011}.

Other aspects of Tarski's account remain distinct from the received one, even in his later texts. In model-theory today, the languages one works with are left uninterpreted until given an interpretation by the interpretation function. The languages Tarski worked with, by contrast, were fully interpreted artificial languages, like those for Riemannian geometry or Peano arithmetic. Thus for Tarski, there is no question of assigning an interpretation to the non-logical constant `0', say, or varying its interpretation across models. Rather, where contemporary model theory varies the interpretation of logical constants across models to determine what follows logically from what, Tarski left these constants interpreted as they were, but replaced them uniformly with variables (always avoiding clashing), whose valuations are then varied accordingly.\footnote{According to \cite[433]{Schiemer2013}, the contemporary practice originates in the work of John Kemeny. See \cite{Kemeny1956} \cite{Kemeny1956b}.} The same point also holds for predicate and relation symbols: where modern practice varies their interpretation, Tarski's replaces them with second-order variables, and varies the valuation of these. \footnote{See e.g. \cite[122-23]{Tarski1941}. Cf. \cite[69]{Etchemendy1988} \cite[448]{Schiemer2013}.} While there is a conceptual difference between the two approaches, both lead to the same material results.

The most debated question concerning Tarski's work from both periods is whether Tarski allowed for domain variation across different classical models, and correspondingly varied or restricted the range of quantification; or whether he employed the logicist practice of assuming a fixed domain of quantification, viz. the actual universe. Unlike the previous case, however, this \textit{does} affect the extension of the class of logical consequences. For instance, if the domain of quantification is not varied, $\exists x \exists y x \ne y$ is a logical truth, and hence follows from, e.g. $\exists x x = x$. But intuitively (and on the variant-domain approach followed today), `there are at least two objects' is not a truth \textit{of logic}, nor does it follow from `there is at least one object'.

\cite[325]{Church1956} had already read Tarski as varying the domain across models. The first paper to have suggested domain variation was \textit{absent} in Tarski's original account appears to have been \cite[43]{Corcoran1972}, though the point is made only in passing. That Tarski held a fixed-domain conception of logical consequence was then defended at length by Etchemendy \cite{Etchemendy1988} \cite{Etchemendy1990} \cite{Etchemendy2008}, and later taken up by Sag\"{u}illo \cite{Saguillo1997} \cite{Saguillo2009} \cite{Corcoran2011}, Bays \cite{Bays2001}, and Mancosu \cite{Mancosu2006} \cite{Mancosu2010a}. A variable-domain reading of \cite{Tarski2002} was accepted by Sher \cite{Sher1991} \cite{Sher1996}, Ray \cite{Ray1996}, and in Stroi\'{n}ska and Hitchcock's introduction to \cite{Tarski2002}, each broadly on grounds of interpretive charity. The most sophisticated proponent of a variable-domain interpretation in Tarski's pre-WWII work is G\'{o}mez-Torrente - see his \cite{Gomez-Torrente1996}  and \cite{Gomez-Torrente2009}. Mancosu has summarized the status of the current debate in \cite{Mancosu2010b}.

Today, all major parties to the discussion agree Tarski uses a fixed-domain framework in his 1936 `on the concept of following logically', this being his broadest and most philosophical discussion of logical consequence in the period. The main points of disagreement concern 1) whether Tarski made use of variable domains where the range of variables was restricted to some more specified domain of discourse - e.g. numbers, points, or segments; and 2) whether Tarski ever changed his mind about domain variation. Sher and Ray assume Tarski held the modern, textbook definition throughout his life. This view has been largely superceded. Readings starting with Etchemendy (1988) and including those of Sag\"{u}illo, Corcoran, and Mancosu, suggest Tarski changed from a fixed to variable domain approach at some point in the late 40s or early 50s. Lastly,  G\'{o}mez-Torrente holds Tarski's views did not change significantly, but neither do they coincide with modern practice. Rather, Tarski accepted a fixed-domain background theory for logical consequence, which permitted techniques for domain relativization in the case of more specific formalized scientific theories.

\cite[251-267]{Gomez-Torrente2009} copiously details cases where Tarski's actual mathematical practice from the same period as his 1936 essay allowed for domain variation. Furthermore, \cite{Tarski1953a}, often regarded as Tarski's first work to explicitly require domain variation in its approach to consequence \cite[367]{Corcoran2011} \cite[65]{Etchemendy1988}, refers his reader to his 1936 paper for formal definitions of its semantical notions, including logical consequence \cite[8, n. 7]{Tarski1953a} \cite[259]{Gomez-Torrente2009}; and Tarski's  \textit{Introduction to Logic and to the Methodology of deductive Sciences}, first published in 1941 with subsequent editions in 1946 and 1965, does not undergo any significant change in its treatment of logical consequence. Lastly, as \cite[365-366]{Corcoran2011} notes, the framework for Tarski's broadest later discussion of the issues involved in his 1936 work, his 1966 lecture `What are logical notions?' \cite{Tarski1986}, is also domain-invariant. In short, Tarski's pre-WWII mathematical work makes use of variable domains; where Tarski makes domain variation is explicit in his post-WWII discussions of consequence, he refers his reader to his earlier work unproblematically; and his broadest later discussion of the issues of his 1936 paper also assumes an invariant domain. All of this suggests a high level of continuity between Tarski's earlier and later work on the subject.

To better understand the continuity as well as the differences between Tarski's practice and modern practice, it may be useful to reflect on the main concerns and motivations behind Tarski's approach. Tarski's main concern was, positively, to secure the foundational unity of the deductive sciences; and negatively, to remove or overcome the main threats to that unity, found especially in G\"{o}del's incompleteness results. Tarski's theory of logical consequence was not meant merely to capture an intuitive notion of following from: it was also meant to serve as a general background theory for accommodating all then-known mathematical deductive practices.\footnote{See \cite{Blok1988} and esp. \cite{Jane2006}.} To give a theory of logical consequence was thus to be engaged in philosophy of science at the most general level. This same attitude persists in \cite{Tarski1986}, where logic is regarded as the most general of the sciences, and logical notions are accordingly identified as those remaining invariant for `all one-one transformations of the space, or universe of discourse, or `world', onto itself' \cite[49]{Tarski1986}. Though its details are different, Tarski's aim, to secure logic as a unified framework for all mathematics, remains one with Russell and Whitehead's \textit{Principia}.

Tarski appears to locate the problem with both the proof-theoretic approach of the Hilbert school and Carnap's approach in a certain relation to \textit{language}. For Tarski, both are too dependent on language, albeit in different ways: Carnap's is linguistically impoverished, since, e.g. is not sufficiently general to extend to languages lacking negation; it is the expressiveness embraced by the proof-theoretic approach to avoid $\omega$-incompleteness, though, that allows G\"{o}del's incompleteness results to go through.\footnote{G\"{o}del's original proof only applied to languages strong enough to formulate Peano Arithmetic, and hence including rules for mathematical induction (or their equivalent). Later, \cite{Rosser1936} and others extended G\"{o}del's incompleteness results, showing they were replicable for all extensions of the the weaker system $Q$, not including induction rules.}. The former failure justifies the shift to the model-theoretic approach; the latter, Tarski's limiting the concept of truth used in this approach so as to restrict self-reference.

For Tarski, in contrast with modern practice, a model does not include an interpretation, but is simply a sequence of objects. As Tarski puts it:
\begin{quote}
One of the concepts which can be defined with the help of the concept of satisfaction is the concept of \textit{model}. Let us assume that, in the language which we are considering, to each extra-logical constant correspond certain variable symbols, and this in such a way that, by replacing in an arbitrary sentence a constant by a corresponding variable, we transform this sentence into a sentential function. Let us further consider an arbitrary class of sentences $L$, and let us replace all extra-logical constants occurring in the sentences of class $L$ by corresponding variables (equiform constants by equiform variables, non-equiform by non-equiform); we shall obtain a class of sentential functions $L'$. An arbitrary sequence of objects which satisfies each sentential function of the class $L'$ we shall call a \textit{model of the class} $L$ (in just this sense one usually speaks about a model of the system of axioms of a deductive theory); if in particular the class $L$ consists of only one sentence $X$, we will simply speak about a \textit{model of the sentence} $X$ \cite[185-186]{Tarski2002}.
\end{quote}
Some examples may be helpful. The sentence `John and Peter are brothers' may be formalized by $B(j, p)$. Since both the relation $B$ and the names $j$ and $p$ are non-logical constants, we replace them all to obtain a class of sentential functions $L' = \{X(x, y), X'(x, y')...\}$. On Tarski's definition, the models of $B(j, p)$ thus end up being those ordered pairs satisfying each sentential function of the form $X(x, y)$. This can be meant in two ways: in the first way, it can mean the models of $B(j, p)$ are those ordered pairs satisfying every binary function. If this were so, the resulting class would be empty, since, e.g. no ordered pair satisfies both the identity function and its converse. And following this line of reasoning, anything would follow from it: since the class of models is empty, it holds vacuously that every model of whatever else would be a model of $B(j, p)$. This isn't Tarski's intention. In the way Tarski did intend this, we regard $X(x, y)$ and $X(x', y')$ as mere notational variants of each other when considered separately, and take the class of models of $B(j, p)$ to be the class of ordered pairs satisfying some arbitrary binary relation which we let be designated by $X$. The class of models thus turns out to be just the class of ordered pairs.\footnote{The proof of this is simple: both the identity and non-identity functions are candidate values for the second-order variable $X$ in $X(x, y)$. Since these partition the class ordered pairs (i.e. every ordered pair satisfies one or the other of these), there is always some function the variable $X$ may be mapped to to include an ordered pair as its arguments mapping to $t$.} This is counterintuitive to the degree one might expect the class of models of the \textit{fully-interpreted} string $B(j, p)$ to simply be $\{<$John, Peter$>\}$. But notice that Tarski's method gives the same result as the modern one, on which $B$, $j$, and $p$ are treated as uninterpreted symbols whose interpretations are varied across models.

Continuing, if we wished to treat the brotherhood relation as logical, we would obtain a different class of sentential functions $L''$ whose models would be the ordered pairs of brothers, and thus including, e.g. both $<$John, Peter$>$ and $<$Peter, John$>$. If, then, we were to let the string $S(j, p)$ mean that John and Peter are siblings, then if both $S$ and $B$ were treated as logical constants, every model of $B(j, p)$  would indeed be a model of $S(j, p)$. If $B$ were treated as non-logical but $S$ were not, some sequences of objects satisfying each sentential function of $L'$ would not satisfy those obtained from $S(j, p)$ - e.g. let $S$ be replaced by a second-order variable denoting the binary function whose output is $t$ just in case its arguments are sisters. If the converse were assumed - i.e. $B$ were logical while $S$ was not - then $S(j, p)$ would still not follow from $B(j, p)$: some ordered pairs of brothers fail to satisfy some sentential function of the form $X(x, y)$. Lastly, if we take neither $B$ nor $S$ as logical constants, then this amounts to the requirement that every sequence satisfying some binary sentential function in $L'$, $X(x, y)$ at the same time satisfies some \textit{other} binary sentential function in $L'$ $X'(x, y)$, and so has countermodels (e.g. that mentioned above where $B$ is given its intended interpretation, but $S$ is interpreted as the sisterhood relation). Here, the equiformity requirement is crucial in securing the correct result. 

In short, though both Tarski's and the modern approach call a consequence $\Gamma \models \phi$ formal when every model of the set $\Gamma$ is at the same time a model of $\phi$, they differ to the degree that the underlying understanding of model differs between them. Tarski interprets `model of $\Gamma$' to mean a sequence of objects satisfying the sentential functions (i.e. constant-free versions of the sentences of $\Gamma$, where like constants are replaced by like variables) obtained from the fully-interpreted class of sentences $\Gamma$. The modern approach takes a model of $\Gamma$ to be an interpretation of the (uninterpreted) strings in $\Gamma$, mapping them to a domain of objects which is arbitrary both with regard to its contents and its number. Tarski's approach corresponds somewhat more fully to the pre-theoretical meaning of `model'; while the modern approach, if somewhat idiosyncratic in its choice of terms, corresponds more fully to the intuitive extension of following formally by allowing variation of the domain. Let us then see how these compare to Buridan's account.
\section{Buridan's theory of formal consequence}
\subsection{Preliminaries}
Buridan's \textit{Treatise on Consequences} divides into four books: the first provides the theory of consequences, then discusses consequences holding between assertoric propositions; the second treats modal consequence; the third and fourth provide provide more detailed discussions of assertoric and modal syllogistic, respectively. 

Buridan's begins book 1 with a discussion of the truth and falsity of propositions (ch. 1), then the causes of the truth of propositions before turning to the definition (ch. 3) and division of consequences (ch. 4). After this, he treats the supposition (ch. 5) and ampliation of terms (ch. 6) and the matter and form of propositions (ch. 7) before turning to his listing of assertoric consequences in chapter 8.

Unlike Tarski, Buridan has no notion of a function, and unsurprisingly has even less the notion of a sentential function. However, the degree to which Buridan's remarks on propositions mimic the role played by the notion of sentential function in Tarski's is surprising. Earlier medieval logic treatises invariably discussed the signification of terms prior to propositions. In doing so, they followed the order charted by Aristotle in the Boethian translations of the \textit{logica vetus}.\footnote{The `old logic', those elements of the Aristotelian logical corpus that never disappeared from the Latin West: Porphyry's \textit{Isagoge} and Aristotle's \textit{Categories} and \textit{On interpretation}. See \cite[in peri herm., prol.]{AquinasDI}, as well as the ordering of materials in Ockham's \cite{OckhamSLI}.} Because terms signified things belonging to the different Aristotelian categories of being, and terms were the principal parts of the proposition, an adequate grasp of propositions was thought to presuppose a correct account of the categories. This was all the more so in the case of syllogistic and other consequences, which themselves presupposed the theory of the proposition. Where Ockham's approach, for instance, was radical in proposing a different and more limited metaphysical basis for logical reasoning \cite{Read2007}, Buridan's ordering of materials in both his \textit{Tractatus de consequentiis} and his \textit{Summulae} is radical in simply postponing the question: what is important first and foremost for Buridan is the role terms play in a sentence.

The first major respect in which Buridan's account differs from Tarski's is in its treatment of the role of temporality in propositions. Tarski's account both takes the number of objects to be fixed and requires constants referring to them to be stripped of any temporal or modal connotation.\footnote{In this respect, Tarski is merely following Russell, Ramsey, and Wittgenstein. See \cite[59ff]{Ramsey1931}.} For Buridan, by contrast, what exists changes from moment to moment, and hence, too, would the domain of a formal semantics faithful to his ideas. And while the syntax of Buridanian statements is not exactly natural Latin, neither does it require the degree of regimentation found in its Tarskian counterpart. With Prior and Kripke and against Quine and Tarski, the propositional edifice upon which Buridan builds his account of consequence retains modality and tense.\footnote{For the influence of Buridan on Prior's work, See \cite{Uckelman2012b}.}

As a special case of the previous remark, \textit{propositions}, too, can come into and out of existence \cite{Klima2004} \cite{DutilhNovaes2005}. This further shows that unlike Tarski, Buridan didn't require the elements of language to themselves lie outside the range of semantic referents. In accord with these motivations, Buridan's account also allows for propositions changing their truth value over time.

Allowing for anachronism, we can say Buridan employs a version of truthmaker semantics. But his `presentism' leads to some modifications when compared to more common accounts of truthmakers, or what Buridan calls \textit{causes of truth} \cite[TC I.1]{Buridan2015}. Typically, presentist approaches to truthmaking require that one give \textit{presently-existing} truthmakers for past- and future-tense statements. These may be existing concrete entities \cite{Cameron2008} \cite{Cameron2011} \cite{Cameron2013}, abstracta \cite{Crisp2007}, or even the entire universe \cite{Bigelow1996}. Buridan, by contrast, employs a version of what Baron has recently called \textit{tensed-truthmaker theory} \cite{Baron2015}. According to Buridan,
\begin{quote}
If Colin's horse, which cantered well, is dead, `Colin's horse cantered well' ... is true because things were in reality as the proposition signifies they were. In the same way `The Antichrist will preach' is true, not because things are in reality as the proposition signifies, but because things will be in reality as the proposition signifies they will be. Similarly, `Something that never will be can be' is true, not because things are as the proposition signifies, but because things can be as it signifies them to be.' And so it is clear that it is necessary to assign causes of truth to different types of propositions in different ways \cite[TC I. 1, 63]{Buridan2015}.
\end{quote}

Where Tarski prefaced his account of consequence by introducing the notion of a model, i.e. a sequence of objects satisfying a sentential function, Buridan uses the notion of the \textit{causes of truth} or falsity of a proposition. A cause of truth of a present-tense assertoric proposition $\phi$ at time $t$ is a state of affairs present at $t$ making the proposition true, provided $\phi$ exists. If $\phi$ does not exist at $t$, it is neither true nor false. In tensed and modal cases the same basic idea is applied, making appropriate adjustments. But where Tarski stratifies the concept of truth, Buridan jettisons it: his account of consequence makes no use of truth apart from that required to arrive at the concept of a cause of truth \cite{Klima2008}. 

For Buridan, the causes of truth of a proposition may change over time. Some propositions have one cause of truth, while others have several. For instance, the proposition, `Socrates is hanging from a basket' has no causes of truth at the time of my writing, since Socrates is dead, and not hanging from a basket. However, at a time $t'$ where Socrates \textit{is} hanging from a basket, Socrates' doing so is a cause of truth of `Socrates is hanging from a basket'. If Socrates does so at $t$ and $t'$, then Socrates' hanging from a basket at $t$ is a cause of truth of the proposition `Socrates is hanging from a basket' at $t$, but not at $t'$, and conversely. At present, `some philosopher is concocting contrived examples for a paper', has my doing so as a cause of truth, though surely my doing so is not the only cause. The proposition `everybody is hanging from baskets!' only ever has at most one cause of truth at a time, namely all existing people hanging from baskets. Alas, this proposition has probably never had any causes of truth.

As we can see from the above, where Tarski's notion of a model is general from the start, countenancing e.g. every object satisfying a unary function from objects to truth as a model of `Socrates runs', Buridan's remains particular at this point, countenancing only Socrates running as a cause of truth.

For Buridan, the relative number of causes of truth a typical quantified subject-predicate proposition can have is conditioned by the \textit{supposition} of its terms. In his \textit{Summulae}, Buridan divides the most common type of supposition, \textit{common material supposition}, into determinate and confused, the latter being subdivided into distributed and merely confused. The subject and predicate of a particular affirmative proposition, as well as the subject of a particular negative, have determinate supposition: each implies the disjunction of all sentences where the determinately suppositing term is replaced by one of its instances, and is implied by any of these. The subject of a universal affirmative has confused distributed supposition, as do both terms of a universal negative proposition: each implies any sentence replacing the confused distributed term with any object falling under it, and is implied by the conjunction of all such sentences. Merely confused proposition is that kind had by the predicate of a universal affirmative proposition: here, one cannot descend from the original sentence to either the conjunction or disjunction of all sentences resulting from replacing the merely confusedly suppositing term with an object falling under it, though one \textit{may} descend from the original sentence to one where the merely confusedly suppositing term is replaced by the term disjunction of all its instances. Buridan explains the relations between these as follows:

\begin{quote}
I say that both terms being undistributed but suppositing determinately, then there are more causes of truth than if one were distributed and the other confused without distribution. This is clear because every cause of truth enough to make ``Every B is A'' true is enough to make ``B is A'' true, but not vice versa. Therefore a proposition [1] has most causes of truth with each term undistributed [2] and fewer with one term distributed and the other confused without distribution, [3] and fewer still with one distributed and the other used determinately without distribution, [4] and fewest of all with both distributed \cite[TC I. 2, 66]{Buridan2015}.
\end{quote}

What Buridan states here has a ready parallel in model theory, namely that every model of a sentence of the form $\forall x \phi$ is a model of `$\exists x \phi$'. Buridan, however extends the theory somewhat further, pointing out that whatever makes a proposition of the form `Every A is \textit{this} B' true also makes `Every A is B' true (i.e. case 3), and that whatever makes `Every A is every B' true also makes `Every A is this B' true (case 4). Buridan is already operating on a highly abstract level in considering cases like 3 and 4, which hardly occur in natural language discussion. And by phrasing the point in terms of distribution rather than by mentioning specific determiners, he shows us he knows this holds across a wide-variety of sentential forms, rather than merely those specifically mentioned above.

What is perhaps surprising is that for Buridan, a cause of truth does not suffice for the truth of a proposition, but only does so on the condition that the proposition itself exist. Buridan introduces this caveat as a way of dealing with certain propositions whose existence falsifies them, that nevertheless describe possible states of affairs. For instance, the proposition `no proposition is negative' is self-falsifying whenever formed, but surely describes a possible state of affairs - indeed, it adequately captures each actual state of affairs before the advent of human speech \cite[TC I. 3]{Buridan2015}.
\subsection{Formal and material consequence}
After laying out the above preliminaries, Buridan provides us first, with a definition, then a division of consequences.

Today, logicians distinguish consequence from hypothetical propositions, usually identifying the latter with conditionals. One then must prove a deduction theorem to establish that $A \models B$ iff $\models A \rightarrow B$. Buridan, by contrast, identifies these: `A consequence is a hypothetical proposition; for it is constituted from several propositions conjoined by the expression `if' or the expression `therefore' or something equivalent' \cite[TC I. 3, 6, alt.]{Buridan2015}. However, as modern practice reserves the term `consequence' for formally valid consequence, Buridan reserves it for true hypotheticals, excluding false ones\cite[TC I. 3, 66]{Buridan2015}. But where the classical emphasis on formal validity arises already in removing non-logical content from the models of a sentence, Buridanian consequences are not as such formal in this way. \footnote{This difference in definition hints at a much deeper one. For Buridan, consequences are always individual sentence tokens, i.e. actually written or spoken hypothetical expressions, which are evaluated as true or false by virtue of determining whether the connections they express hold in all possible situations (including those where the expressions themselves do not exist, and hence are neither true nor false). For Tarski and the modern approach, by contrast, consequences are \textit{never} actual sentences, both because of the aforementioned abstraction at the level of the models of a sentential function, and because the antecedent $\Gamma$ of a classical consequence $\Gamma \models \phi$ is always at least denumerably infinite, since it is closed under entailment.}

After considering definitions of consequence in terms of 1) the impossibility of the antecedent being true and the consequent not so, 2) the impossibility of the antecedent being true and the consequent false \textit{when both formed}, and 3) the impossibility of things being as the antecedent signifies without being as the consequent signifies, Buridan ultimately settles on the following, definition of consequence: 

\begin{quote}
A consequence is a hypothetical proposition composed of an antecedent and consequent, indicating the antecedent to be antecedent and the consequent to be consequent; this designation occurs by the word `if' or by the word `therefore' or an equivalent, as was previously stated \cite[TC I. 3, 67]{Buridan2015}.
\end{quote}

Unlike the model-theoretic definition, Buridan's is deflationary in spirit: Buridan takes `antecedent' and `consequent' to apply to the respective parts of a hypothetical proposition precisely when `consequence' applies to the whole. Thus, whether the definition is materially adequate or not,\footnote{It is not. See [reference omitted].} it does nothing to further determine either the extension or the intension of `consequence' beyond what is already given in the name itself.

Buridan divides consequences into formal and material, dividing the latter into simple and as-of-now consequences. A simple consequence is one where things cannot be as the antecedent signifies and not as the consequent signifies. An as-of-now consequence, one where things cannot \textit{now} be as the antecedent signifies, without also being as the consequent signifies. Thus, as-of-now consequence limits those cases considered by simple consequence to the present situation alone. Thus, every simple material consequence is an as-of-now material consequence, but not conversely. 

Buridan explains the division between formal and material consequence as follows: 
\begin{quote}
A consequence is called `formal' if it is valid in all terms retaining a similar form. Or, if you want to put it explicitly, a formal consequence is one where every proposition similar in form that might be formed would be a good consequence.

...A material consequence, however, is one where not every proposition similar in form would be a good consequence, or, as it is commonly put, which does not hold in all terms retaining the same form \cite[TC I. 4, 68]{Buridan2015}.
\end{quote}

Buridan continues: 
\begin{quote}
It seems to me that no material consequence is evident in inferring except by its reduction to a formal one. Now it is reduced to a formal one by the addition of some necessary proposition or propositions whose addition to the given antecedent produces a formal consequence \cite[TC I. 4, 68]{Buridan2015}.\footnote{TC 1.4.3.}
\end{quote}

Where the former passage shows formal and material consequence are on equal footing with respect to their \textit{signification} - both are true hypothetical propositions - the latter shows they are not so with respect to their evidential status: a material consequence is only evident in inference if it can be transformed into a formal one by appropriate additions to the antecedent. One might get the impression from this that for Buridan, material consequences are all enthymemes.\footnote{Cf. Burley (1955), 66.} But Buridan lists enthymemes alongside examples and inductions as only one kind of material consequence \cite[TC III. 1, 113]{Buridan2015}; and Buridan's treatment of dialectical topics, inductions may proven not `by virtue of being a formal consequence or by being reduced to a formal consequence, but by the natural inclination of the understanding towards truth' \cite[SD 6.1.5]{BuridanLoci}. In this way, the peculiar importance of formal consequence lies not in its preserving \textit{truth}, but \textit{evidence}.

But to know which consequences exactly are formal, one must know what the form of a proposition is. And just as in both Tarski's earlier and later work, this is determined by a partition of the different elements of a sentence. Buridan writes:

\begin{quote}
I say that when we speak of matter and form, by the matter of a proposition or consequence we mean the purely categorematic terms, namely the subject and predicate, setting aside the syncategoremes attached to them by which they are [1] conjoined [2] or denied [3] or distributed [4] or given a certain kind of supposition; we say all the rest pertains to form \cite[TC I. 7, 74]{Buridan2015}.
\end{quote}

There are two central differences between Buridan's definition and its Tarskian counterpart. First, where Tarski's division is a fixed division of terms in a \textit{language} into two different \textit{kinds}, Buridan's division is one of terms in a \textit{sentence} into two different \textit{roles}. Thus, for instance, in the sentence `if is a syncategoreme, therefore if is a word', Buridan's analysis correctly characterizes `if' as a categorematic term, while Tarski's requires it be treated as a logical constant. Second, where Tarski's approach prioritizes determining the set of logical constants of a language, Buridan's begins by defining the \textit{categorematic} terms of a sentence, i.e. the analogue of classical non-logical constants, and then defines the syncategoremata of a sentence as those not belonging to among the categorical terms of the sentence. The categorematic terms are simply those operating as the subject and predicate of the sentence.\footnote{A note on the language of `syncategoremata': the phrase `syncategorematic terms' does not occur in Buridan, nor to my knowledge in other medieval discussions of consequence. Terms are those words in which every sentence `bottoms out' (hence the name `term', i.e. end or limit), and so are just those words against which syncategoremes are divided.}

Buridan lists four types of words as pertaining to form: 1) those conjoining the subject and the predicate (e.g. `is'); 2) those separating the subject and predicate (e.g. `not'); 3) those giving the terms a certain distribution (quantifiers); 4) those giving terms a certain kind of supposition (e.g. modal, tense, and other intensional operators). These last two are the subjects to which Buridan's discussions of supposition and ampliation in chapters five and six pertain. Notably absent from this list are propositional connectives, which Buridan doesn't consider in the TC.

Though Buridanian formal consequences may be represented schematically, these consequences are never themselves schematic,\footnote{This is also true on Tarski's account, though it is not so on the received classical analysis. The basic reason for the latter is the decision to regard the constant symbols as uninterpreted.} but rather remain individual hypothetical propositions. As such, there is no problem on Buridan's account about whether the \textit{ordering} and choice of schematic variables in a schematic consequence belongs to its matter or form.\footnote{I thank Milo Crimi for bringing this problem to my attention.} For Buridan, while different good consequences may be representable by the same schema (e.g. different instances of \textit{modus ponens}); while these same consequences may be representable by other schemata (i.e. by uniformly replacing the schematic variables used in the first schema with others); and while schemata for good and bad formal consequences may have the same ordering of their syncategorematic parts (e.g. \textit{modus ponens} and affirming the consequent): because schematic consequences are not properly consequences at all for Buridan, these problems disappear. Buridan formal consequences are hypothetical propositions of a natural language; it is not because they belong to the same schema that they are formal consequences; rather, these formal consequences evidently belong to an equivalence class, and because of this can be represented schematically under the same form.

\section{Formality from Tarski back to Buridan}
Having set Buridan's, Tarski's, and the standard classical accounts of formal consequence in order, we can now contrast them summarily. Doing so thereby provides us with a condition requisite for providing an adequate genealogy of the Tarskian concept, i.e. an account of the conditions that had to arise between Buridan and Tarski's account before Tarski's account became a real conceptual possibility. With this in mind, we first summarize the differences between the Buridanian and Tarskian accounts of formal consequence; then, we list historical conditions necessary for arriving at the Tarskian account from the Buridanian one.

Both modern and Tarskian approaches begin with a partition of all terms of a \textit{language} into logical and non-logical terms; Buridan's partition of terms into categorical and syncategorematic occurs not at the level of a language, but at that of the sentence. 

Tarski's project prioritizes determining the logical terms of a language, the determination of the set of non-logical terms falling out of this. Buridan's partition begins by determining those terms pertaining to the matter of the sentence, fixing the set of formal terms in a sentence as the complement of those pertaining to the matter. Where Tarski's partition is one of different types of terms in a language, Buridan's is of different roles had by terms in a sentence. For Buridan, the terms pertaining to the matter of a sentence are its subjects and predicates.

Tarskian consequence was designed for recursively defined artificial languages, particularly those being developed in mathematics. Buridanian consequence was designed to capture Buridan's stilted fourteenth-century scholastic Latin. Leaving humanist qualms aside, the latter remained a natural language, albeit one making use of mild regimentation when doing so aided discussion. Buridan counts the copula, negation, modalities, tenses, quantifiers, intentional operators, as well as disjunction, conjunction and negation for terms among the formal parts of a sentence. But because he explains the formal parts of a sentence as those affecting the supposition of \textit{terms}, he does not mention sentential connectives as pertaining to form. Tarski's approach discounted modalities, tenses, and intensional operators, and was initially silent on the role of identity, though his later approach explicitly countenanced identity as a logical notion. Since then, modalities and other intensional operators have become standard extensions of classical logic.

For Tarski, consequences are distinguished from hypothetical propositions, not least because the set of premises from which a consequent is derived is closed under entailment, hence countably infinite. Buridan, by contrast, explicitly defines a consequence as a hypothetical proposition.

Where Tarski provides an informative definition of consequence in terms of models, Buridan provides a deflationary one in terms of the correlative notions of antecedent and consequent. However, the work done by the notion of a model on Tarski's account is mimicked by that done by the notion of a cause of truth on Buridan's. 

On the received classical account, a model of a sentence $\phi$ in a language $L$ consists of a domain $D$ and an interpretation $I$, i.e. a mapping of the sentences of $L$ recursively determined by a mapping of terms to elements in $D$ and n-ary predicates to sets of $n$-tuples in $D^{n}$.

On Tarski's account, a model of a set of sentences $\Gamma$ is a sequence of objects in a fixed domain satisfying the sentential functions obtained by uniformly replacing each non-logical constant in the sentences of $\Gamma$ with variables of the appropriate order and arity. 

The differences between the received classical and Tarskian understandings of a model thus lead to differences in their understanding of both the intension and extension of the concept of formal consequence. Both the Tarskian and received classical accounts of the models of a sentence, however, are general from the beginning: for instance, the classical models of an atomic sentence will not be the objects making it true on the intended interpretation of its non-logical constants, but those making it true on \textit{any} interpretation; and the Tarskian models will be sequences satisfying any sentential function of the same form as the initial sentence.

Buridan's account of causes of truth, by contrast, maps hypothetical propositions to states sufficient to make them true on their \textit{intended} interpretation. The determination of the relative number of causes of truth a sentence has is given by the supposition of its terms, i.e. the manner in which one is permitted to descend from a general term modified by a determiner to a new sentence or sentences replacing the determined general term with a name (names) for an individual(s) falling under it. On Buridan's account, the causes of truth of a proposition are relative to a time of utterance; the models of a Tarskian sentence are not; and while not fixed, classical models are relativized in a way not based on external circumstances, but arbitrarily. On Buridan's account, formality is then achieved by the determination of the equivalence class of a hypothetical proposition: a Buridanian consequence is formal iff for every proposition equivalent in form to it that could be formed, it is impossible for things to be as the antecedent signifies without being as the consequent signifies (leaving aside problems Buridan recognizes with talk about things being as propositions signify).

Let us now say that for contingent concepts $C$, $C'$, the concept $C'$ is constitutive of $C$ if the existence of $C'$ is necessary for that of $C$, i.e. there is no possible situation in which $C$ exists but $C'$ does not. Let us further say an event $e$ is a \textit{necessary historical condition} with respect to the existence of $C$ if for linearly ordered times $t$, $t'$ where $t<t'$, at some $t''$ such that $t<t''<t'$, $e$ generates some concept $C''$ at $t''$ constitutive of $C$ not present at $t$. In this way, we see that though $C'$ is necessary for $C$, a necessary historical condition $e$ generating $C'$ is neither sufficient nor absolutely necessary for the existence of $C$, though it is sufficient for the existence of $C'$.

Those developments that \textit{were} necessary historical conditions for the development of Tarski's account from the Buridanian one are comparatively few, but central. The first is the development of the concept of a model; the second, that of a sentential function; the third, accordingly, that of a function. Lastly, the decision to regard antecedents as premise sets closed under entailment, and hence infinite, presupposed the development of recursion theory and its application to logical entailment.

On the other hand, some elements of Tarski's account were straightforwardly available to Buridan, but not taken up by him. Tarski's rejection of modality is not historically dependent upon post-14th century developments. An understanding of the parts of consequence as non-linguistic was accepted in the 14th century by Walter Burley \cite{Bulthuis2016}. And the assumption of a fixed, eternalist domain is present in Buridan's own discussion of natural supposition \cite[SD 4.3.4]{BuridanKlimaSD}. In assuming the same terms may supposit differently (e.g. for themselves) in different sentences, Buridan implicitly rejects Tarski's construal of different parts of a language as belonging to different kinds.\footnote{Even if Tarski's division exacerbates a tendency, already found in Buridan, to prescind from treating the meaning of terms prior to their propositional role.} Other differences, including Buridan's decisions to identify consequences and hypothetical propositions, to determine causes of truth relative to a time, and to distinguish formal consequence from logical consequence as such, represent further philosophical disagreements.

As for motivations, one of the main ones behind Tarski's approach to languages - the complete elimination of equivocation from scientific language - was present in a different form in Ockham's adoption of \textit{mental}, rather than spoken or written, language as his point of departure \cite{Trentman1970} \cite{Spade1980} \cite{Chalmers1999}, but not in Buridan. Buridan does not require the elimination of equivocation, hence neither does he have the concern one finds in Tarski with the consistency of languages.\footnote{This is part of what allows Buridan to treat the Liar paradox locally, rather than instituting a global ban on self-reference. See \cite[SD 9.2.6]{BuridanKlimaSD}. Cf. \cite{Klima2004} \cite{Klima2008} \cite{DutilhNovaes2011b} \cite{Benetreau-Dupin2015}}

Tarski's worries about Carnap's account of semantic consequence don't arise for Buridan, either: natural languages are sufficiently robust, and indefinitely extendable, thus sufficient to encounter most of Tarski's concerns with impoverished recursive languages.\footnote{Cf. \cite{BarcanMarcus1978}.} The major exception to this is superdenumerable domains such as the real numbers, points of geometrical space, etc., which Buridan's theory was clearly not designed to handle. This discovery, while not a necessary historical condition for the development of the semantic approach to consequence, was and remains an important motivator for it.


\section{Conclusion}
The concept of formal consequence in classical logic today holds perfect verbal agreement with Tarski's 1930s definition that $\Gamma \models \phi$ iff every model of $\Gamma$ is at the same time a model of $\phi$. But behind this verbal agreement lies a substantive disagreement, grounded in different concepts of a model. Today's classical models interpret uninterpreted linguistic strings by mapping them to a domain of arbitrarily many objects. Tarskian models, by contrast, are those sequences of objects satisfying sentential functions obtained from interpreted sentences, mapped to the fixed domain representing all objects in the world. Tarski's account represents a genuine development from the Buridanian account to the degree that it employs the concepts of a model and a sentential function, as well as elements of recursion theory that were unavailable to Buridan. Other differences, however, represent more substantive disagreements. Buridan's presentism, his acceptance of modality and tense, his acceptance of variable domains, his prioritization of the determination of the material parts of the sentence over the formal, his decision to adopt a token-based semantics grounded in natural languages, all were taken up \textit{against} analogues of the contrary positions found in Tarski in Buridan's own time. In other ways, the difference between Buridan and Tarski's approach to consequence is not so wide as their chronological distance from each other would suggest. In contrast with modern practice, neither construes the \textit{relata} of formal consequence schematically; Buridanian causes of truth form analogues to the Tarskian concept of models of a sentential function; and both Buridanian and Tarskian accounts of following formally are given in terms of substitution - A Buridanian formal consequence is good if all sentences that could be formed by uniform substitutions on its categorematic terms are good, a Tarskian one if it is invariant under satisfaction of sentential functions obtained from it by substituting its non-logical constants with variables. Given this closeness, it is perhaps unsurprising that may of the genuine developments in formal logic over the past sixty years have involved a reappropriation of the Buridanian standpoint on just those topics where he disagrees with Tarski. In this reappropriation of the best elements of Buridan's account into the context brought about by genuine developments since it, one might hope to find progress toward ... well, how things are signified to be.
\bibliography{jacob}
\bibliographystyle{plain}
\end{document}
